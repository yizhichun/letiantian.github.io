<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="乐天笔记, 樂天笔记, 编程" />





  <link rel="alternate" href="/atom.xml" title="樂天笔记" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/content/images/favicon.ico?v=5.1.1" />






<meta property="og:type" content="website">
<meta property="og:title" content="樂天笔记">
<meta property="og:url" content="http://www.letiantian.me/page/2/index.html">
<meta property="og:site_name" content="樂天笔记">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="樂天笔记">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.letiantian.me/page/2/"/>





  <title>樂天笔记</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  <img class='bg-image' src="/content/images/bg.jpg" />

  







  <script type="text/javascript">
    (function() {
      var hm = document.createElement("script");
      hm.src = "//tajs.qq.com/stats?sId=62535551";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>









  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">樂天笔记</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-topics">
          <a href="/topics" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-flask"></i> <br />
            
            专题
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://www.letiantian.me/2015-06-22-update-faster/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Letian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/content/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="樂天笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2015-06-22-update-faster/" itemprop="url">如何快速更新数据库中的百万条数据</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2015-06-22T14:40:27+08:00">
                June 22nd 2015
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>2015-06-22</p>
<p>环境：ubuntu 14.04，Mysql 5.6，python 2.7。</p>
<p>本文使用python的MySQLdb这个库，<a href="http://zetcode.com/db/mysqlpython/">MySQL Python tutorial</a>这个教程很赞。</p>
<p>MySQLDBdb处理INSERT、UPDATE、DELETE时需要显式得commit()才能使更新有效，这也意味着commit之前的更新语句是放在一个事务中的。</p>
<blockquote>
<p>For databases that support transactions, the Python interface silently starts a transaction when the cursor is created. The commit() method commits the updates made using that cursor, and the rollback() method discards them. Each method starts a new transaction.</p>
</blockquote>
<p>对比如下：</p>
<table>
<thead>
<tr>
<th>更新方式</th>
<th>总时间(ms)</th>
<th>rows</th>
<th>平均(ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>57831</td>
<td>1000</td>
<td>57.8</td>
</tr>
<tr>
<td>2</td>
<td>89695</td>
<td>10</td>
<td>896</td>
</tr>
<tr>
<td>3</td>
<td>92941</td>
<td>40×10000</td>
<td>0.23</td>
</tr>
<tr>
<td>4</td>
<td>47956</td>
<td>40×10000</td>
<td>0.119</td>
</tr>
<tr>
<td>5</td>
<td>28407</td>
<td>40×10000</td>
<td>0.071</td>
</tr>
<tr>
<td>6</td>
<td>3272</td>
<td>48×10000</td>
<td>0.008</td>
</tr>
</tbody>
</table>
<p>方式1是单线程，where使用了索引，一个更新对应一个commit。<br>方式2是单线程，where没有使用索引，所有更新对应一个commit。<br>方式3是单线程，where使用了索引，所有更新对应一个commit。<br>方式4使用了2个进程来更新，where使用了索引，每个进程里的所有更新对应一个commit。<br>方式5使用了4个进程来更新，where使用了索引，每个进程里的所有更新对应一个commit。<br>方式6是在一个update语句里面更新所有的数据。  </p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2015-06-22-update-faster/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://www.letiantian.me/2015-05-27-java-concurrency-summary/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Letian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/content/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="樂天笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2015-05-27-java-concurrency-summary/" itemprop="url">Java并发概念汇总</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2015-05-27T10:19:02+08:00">
                May 27th 2015
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>2015-05-27</p>
<p>看了《Java编程思想 第4版》<code>并发</code>这一章，觉得有必要整理一下其中的概念。</p>
<h2 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h2><p>为什么要并发？ 比如因为IO操作遇到了阻塞，CPU可以转去执行其他线程，这时并发的优点就显示出来了：更高效的利用CPU，提高程序的响应速度。</p>
<p>Java的线程机制是抢占式的，会为每个线程分配时间片。</p>
<h3 id="线程中断与上下文切换"><a href="#线程中断与上下文切换" class="headerlink" title="线程中断与上下文切换"></a>线程中断与上下文切换</h3><p><a href="http://www.cnblogs.com/ktgu/p/3529144.html">并发编程 - 多线程的代价及上下文切换</a><br><a href="http://ifeve.com/context-switching-and-multi-processor/">上下文切换与多处理器</a></p>
<h3 id="Java本身还有另外一个“线程中断”"><a href="#Java本身还有另外一个“线程中断”" class="headerlink" title="Java本身还有另外一个“线程中断”"></a>Java本身还有另外一个“线程中断”</h3><p><a href="http://www.infoq.com/cn/articles/java-interrupt-mechanism">详细分析Java中断机制</a>  </p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2015-05-27-java-concurrency-summary/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://www.letiantian.me/2015-05-26-a-guide-to-svd-for-collaborative-filtering/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Letian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/content/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="樂天笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2015-05-26-a-guide-to-svd-for-collaborative-filtering/" itemprop="url">基于SVD的协同过滤</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2015-05-26T10:11:06+08:00">
                May 26th 2015
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>2015-05-26</p>
<p>本文是下面这篇论文的阅读笔记：</p>
<blockquote>
<p>Ma C C. A Guide to Singular Value Decomposition for Collaborative Filtering[J]. 2008.</p>
</blockquote>
<p>注意，这里的SVD，和经典的分解为3个矩阵的方法是不一样的。</p>
<h2 id="提出问题"><a href="#提出问题" class="headerlink" title="提出问题"></a>提出问题</h2><p>直接使用传统的SVD进行协同过滤的的效果可能会很差，所以考虑一些SVD的变体来进行协同过滤。</p>
<p>用户可以对电影评分，分数范围是1到5。一般，一个用户不会给所有的电影都评分，有些用户评分的电影很多，有些用户只给很少的电影打评分。</p>
<p>一般评分矩阵中的0代表着对应的用户没有给对应的物品（电影）评分，0并不能看作分值。</p>
<p>设[latex]V[/latex]是大小为<code>n×m</code>的评分矩阵，n个用户，m个电影。[latex]I[/latex]也是大小为<code>n×m</code>的矩阵，其元素的值只有0和1，若[latex]I_{ij}[/latex]为1，则用户i给物品j打过分，这也意味着[latex]V_{ij}[/latex]不为0；若[latex]I_{ij}[/latex]为0,则用户i没给物品j打过分，这也意味着[latex]V_{ij}[/latex]为0。故矩阵[latex]I[/latex]是矩阵[latex]V[/latex]的指示器（indicator）。矩阵[latex]V[/latex]也可以以稀疏矩阵的形式保存，只保存打过分的数据。</p>
<p>矩阵[latex]V[/latex]作为协同过滤算法的训练数据，而协同过滤算法的目标是预测某个用户对某个物品的评分（该用户之前没有对该物品评分）。</p>
<p>算法的评测标准：一般是比较真实评分和预测的评分之间的误差，例如<a href="http://en.wikipedia.org/wiki/Mean_squared_error" target="_blank" rel="external">Mean squared error</a>、<a href="https://www.kaggle.com/wiki/RootMeanSquaredError" target="_blank" rel="external">Root Mean Squared Error</a>。</p>
<h2 id="算法1：Batch-learning-of-Singular-Value-Decomposition"><a href="#算法1：Batch-learning-of-Singular-Value-Decomposition" class="headerlink" title="算法1：Batch learning of Singular Value Decomposition"></a>算法1：Batch learning of Singular Value Decomposition</h2><p>设n个用户，m个物品，<code>n×m</code>大小的矩阵[latex]V[/latex]是评分矩阵，大小为<code>n×m</code>的矩阵[latex]I[/latex]作为[latex]V[/latex]指示器。SVD算法的目标是找到两个矩阵：<code>f×n</code>大小的[latex]U[/latex]作为用户的特征矩阵，<code>f×m</code>大小的[latex]M[/latex]作为物品的特征矩阵。预测函数[latex]p[/latex]根据[latex]U[/latex]和[latex]M[/latex]预测评分。</p>
<p>[latex]V_{ij}[/latex]的预测值为：</p>
<p>[latex]<br>p(U_{i}, M_{j})<br>[/latex]</p>
<p>其中，[latex]U_{i}[/latex]为用户i的特征向量（feature vector，不是eigenvector，f个元素），[latex]M_{j}[/latex]为物品j的特征向量（f个元素），这两个特征向量从矩阵[latex]U[/latex]和[latex]M[/latex]中直接拿就行了。</p>
<p>然后，我们要最小化下面的式子：</p>
<p><img src="/content/images/2015/05/2015-05-26-svd-01.png" alt=""></p>
<p>其中，[latex]k_{u}[/latex]和[latex]k_{m}[/latex]是防止过拟合的正则化系数，是两个已知的擦书，需要我们自己事先指定。</p>
<p>函数[latex]p[/latex]的一般实现如下：</p>
<p>[latex]<br>p(U_{i}, M_{j}) = U_{i}^{T}M_{j}<br>[/latex]<br>就是两个向量的内积（数量积）。</p>
<p>不过，V中的评分是在<code>[a,b]</code>这个范围里，其中<code>a</code>是最小的评分，<code>b</code>是最大的评分。所以预测函数优化为：</p>
<p><img src="/content/images/2015/05/2015-05-26-svd-02.png" alt=""></p>
<p>好了，现在对于<code>公式(2)</code>，[latex]I,V,n,m,p,k_{u},k_{m}[/latex]都是已知的，通过最小化<code>公式(2)</code>就可以得到[latex]U和M[/latex]。</p>
<p>可以用梯度下降解决这个问题，下面两个式子是负向的梯度：</p>
<p><img src="/content/images/2015/05/2015-05-26-svd-03.png" alt=""></p>
<p>而梯度很明显是：</p>
<p>[latex]<br>\nabla{U_{i}} = \frac{\partial{E}}{\partial{U_{i}}} \\<br>\nabla{M_{j}} = \frac{\partial{E}}{\partial{M_{j}}}<br>[/latex]</p>
<p>由此，得到下面的算法：</p>
<ul>
<li><p>给矩阵U、M赋初始值（例如使用随机值），建议使用下面的方法赋值：<br><img src="/content/images/2015/05/2015-05-26-svd-04.png" alt=""><br>其中，[latex]\bar{V}[/latex]是指V中评分的平均值，a是i所有评分的最小值，f是用户和物品在新特征空间下的维度，<code>n(r)</code>是基于区间[-r, r]生成均匀分布的随机数，r取一个较小的值就行了。</p>
</li>
<li><p>设置学习速率[latex]\mu[/latex]，重复下面两个步骤直到评估方法RMSE的值开始上升：<br>(a). 计算梯度[latex]\nabla{U}和\nabla{M}[/latex]<br>(b). 更新U和M：[latex]U\leftarrow U- \mu \nabla{U}，~~M\leftarrow M- \mu \nabla{M}[/latex]  </p>
</li>
</ul>
<p>迭代停止的判断条件可以有很多，例如RMSE基本不变，或者U、M基本不变时停止迭代。</p>
<p>批量学习（Batch learning）是SVD的标准方法。</p>
<h2 id="算法2：Incomplete-incremental-learning-of-Singular-Value-Decomposition"><a href="#算法2：Incomplete-incremental-learning-of-Singular-Value-Decomposition" class="headerlink" title="算法2：Incomplete incremental learning of Singular Value Decomposition"></a>算法2：Incomplete incremental learning of Singular Value Decomposition</h2><p>对用户i，目标函数是：<br><img src="/content/images/2015/05/2015-05-26-svd-05.png" alt=""><br>负方向梯度为：<br><img src="/content/images/2015/05/2015-05-26-svd-06.png" alt=""><br>对于用户i来说，如果[latex]I_{ij}=0[/latex]，即用户i未对物品j评分，则[latex]M_{j}[/latex]的梯度为0，不会造成M的更新。</p>
<p>算法如下：</p>
<p><img src="/content/images/2015/05/2015-05-26-svd-07.png" alt=""></p>
<h2 id="算法3：Complete-incremental-learning-of-Singular-Value-Decomposition"><a href="#算法3：Complete-incremental-learning-of-Singular-Value-Decomposition" class="headerlink" title="算法3：Complete incremental learning of Singular Value Decomposition"></a>算法3：Complete incremental learning of Singular Value Decomposition</h2><p>这个方法中的目标函数，以及对应的负方向梯度如下：<br><img src="/content/images/2015/05/2015-05-26-svd-08.png" alt=""></p>
<p>算法如下：<br><img src="/content/images/2015/05/2015-05-26-svd-09.jpg" alt=""></p>
<h2 id="算法4：Batch-learning-of-SVD-with-Momentum"><a href="#算法4：Batch-learning-of-SVD-with-Momentum" class="headerlink" title="算法4：Batch learning of SVD with Momentum"></a>算法4：Batch learning of SVD with Momentum</h2><p>这是对算法1的修改：<br><img src="/content/images/2015/05/2015-05-26-svd-10.png" alt=""></p>
<h2 id="更多"><a href="#更多" class="headerlink" title="更多"></a>更多</h2><blockquote>
<p>Ma C C. A Guide to Singular Value Decomposition for Collaborative Filtering[J]. 2008.</p>
</blockquote>
<p>本文的内容都来自这篇论文，论文中<strong>Further Improvements</strong>章节还提到了在目标函数中添加针对用户和物品的偏置向量，在得到U和M的同时，得到偏置向量，这种方法的评估效果会更好些。</p>
<hr>
<blockquote>
<p>Paterek A. Improving regularized singular value decomposition for collaborative filtering[C]//Proceedings of KDD cup and workshop. 2007, 2007: 5-8.</p>
</blockquote>
<p>里面提到了若干基于SVD的算法，还提到了一些有趣的协同过滤算法，例如基于聚类的协同过滤算法。</p>
<hr>
<blockquote>
<p>Funk, Simon. “Netflix update: Try this at home.” (2006).</p>
</blockquote>
<p>放在博客里的一篇有名的文章。</p>
<hr>
<blockquote>
<p>Koren, Yehuda. “Factorization meets the neighborhood: a multifaceted collaborative filtering model.” Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2008.</p>
</blockquote>
<p>SVD++就在这里。 关于SVD++：<br><a href="http://www.recsyswiki.com/wiki/SVD%2B%2B" target="_blank" rel="external">SVD++ - recsyswiki</a>、<br><a href="http://superjom.duapp.com/machine-learning/svd1.html" target="_blank" rel="external">推荐系统常用模型(2) – SVD/SVD++</a>、<br><a href="http://www.quora.com/Whats-the-difference-between-SVD-and-SVD++" target="_blank" rel="external">What’s the difference between SVD and SVD++?</a>。</p>
<hr>
<blockquote>
<p>Koren, Yehuda. “The bellkor solution to the netflix grand prize.” Netflix prize documentation 81 (2009).</p>
</blockquote>
<p>（完）</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://www.letiantian.me/2015-05-25-bayes-text-classify-system-db-design/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Letian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/content/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="樂天笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2015-05-25-bayes-text-classify-system-db-design/" itemprop="url">基于贝叶斯的文本分类系统的数据库设计</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2015-05-25T22:59:40+08:00">
                May 25th 2015
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>2015-05-25</p>
<p>本博客中贝叶斯相关的文章：</p>
<p><a href="/2014-05-20-naive-bayes/">使用朴素贝叶斯分类器划分邮件</a><br><a href="/2014-10-12-three-models-of-naive-nayes/">朴素贝叶斯的三个常用模型：高斯、多项式、伯努利</a><br><a href="/2015-03-31-bayes-classifier-for-text/">基于贝叶斯的文本分类实战</a>  </p>
<p>本文以使用<strong>多项式贝叶斯模型</strong>为例。该模型在文本分类这一领域的正确率一般都比较高，而且有一个很大的有点，就是支持增量训练。</p>
<p>在该模型下：</p>
<pre><code class="text">先验概率P(c)= 类c下单词总数/整个训练样本的单词总数

类条件概率P(tk|c)=(类c下单词tk在该类下各个文档中出现过的次数之和+1)/(类c下单词总数+|V|)
</code></pre>
<p><code>|V|</code>是整个数据集中单词去重后的数量。</p>
<p>下面的数据来自<a href="http://blog.163.com/jiayouweijiewj@126/blog/static/1712321772010102802635243/" target="_blank" rel="external">基于naive bayes的文本分类算法</a>。<em>这篇文章中有一个小的计算失误（在计算新样本的类别时）。</em></p>
<table><thead><tr><th>文档ID</th><th>文档内容</th><th>文档类别</th></tr></thead><tbody><tr><td>1</td><td>Chinese Beijing Chinese</td><td>yes</td></tr><tr><td>2</td><td>Chinese Chinese Shanghai</td><td>yes</td></tr><tr><td>3</td><td>Chinese Macao</td><td>yes</td></tr><tr><td>4</td><td>Tokyo Japan Chinese</td><td>no</td></tr></tbody></table>


<p>由上面可以得到：</p>
<table><caption>单词计数表</caption><thead><tr><th>单词\文档类别</th><th>yes</th><th>no</th></tr></thead><tbody><tr><td>Chinese</td><td>5</td><td>1</td></tr><tr><td>Beijing</td><td>1</td><td>0</td></tr><tr><td>Shanghai</td><td>1</td><td>0</td></tr><tr><td>Macao</td><td>1</td><td>0</td></tr><tr><td>Japan</td><td>0</td><td>1</td></tr><tr><td>Tokyo</td><td>0</td><td>1</td></tr></tbody></table>


<table><caption>汇总表</caption><thead><tr><th>属性</th><th>值</th></tr></thead><tbody><tr><td>单词总数</td><td>11</td></tr><tr><td>单词去重总数</td><td>6</td></tr><tr><td>属于yes的文档下的单词总数</td><td>8</td></tr><tr><td>属于no的文档下的单词总数</td><td>3</td></tr><tr><td>属于yes的文档数</td><td>3</td></tr><tr><td>属于no的文档数</td><td>1</td></tr></tbody></table>

<p>根据上面的公式，有</p>
<pre><code class="text">P(yes) = 8/11
p(no)  = 3/11
P(Chinese | yes)=(5+1)/(8+6)=6/14=3/7  
P(Japan | yes)=P(Tokyo | yes)= (0+1)/(8+6)=1/14  
P(Chinese|no)=(1+1)/(3+6)=2/9  
P(Japan|no)=P(Tokyo| no) =(1+1)/(3+6)=2/9
</code></pre>
<p>所以，对于新样本<code>Chinese Chinese Chinese Tokyo Japan</code>，有：</p>
<pre><code class="text">P(yes | d)
=P(Chinese|yes)×P(Japan|yes)×P(Tokyo|yes)*P(c)
=(3/7)^3×1/14×1/14×8/11
=216/739508
≈0.00029208  

P(no | d)
= P(Chinese|no)×P(Japan|no)×P(Tokyo|no)*P(c)
=(2/9)3×2/9×2/9×3/11
=96/649539
≈0.00014780
</code></pre>
<p>故新样本属于yes这个分类。</p>
<p>根据上面的思路，可知数据库中需要两个表，一个单词计数表，一个汇总表，这两个表和上面的两个表格相同。</p>
<p>伯努利模型类似。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://www.letiantian.me/2015-05-25-nmf-svd-recommend/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Letian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/content/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="樂天笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2015-05-25-nmf-svd-recommend/" itemprop="url">矩阵分解在推荐系统中的应用：NMF和经典SVD实战</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2015-05-25T19:25:06+08:00">
                May 25th 2015
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>2015-05-25</p>
<p>本文以NMF和经典SVD为例，讲一讲矩阵分解在推荐系统中的应用。</p>
<h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><table><thead><br><tr><th>item\user</th><th>Ben</th><th>Tom</th><th>John</th><th>Fred</th></tr></thead><br><tbody><br><tr><td>item 1</td><td>5</td><td>5</td><td>0</td><td>5</td></tr><br><tr><td>item 2</td><td>5</td><td>0</td><td>3</td><td>4</td></tr><br><tr><td>item 3</td><td>3</td><td>4</td><td>0</td><td>3</td></tr><br><tr><td>item 4</td><td>0</td><td>0</td><td>5</td><td>3</td></tr><br><tr><td>item 5</td><td>5</td><td>4</td><td>4</td><td>5</td></tr><br><tr><td>item 6</td><td>5</td><td>4</td><td>5</td><td>5</td></tr><br></tbody></table>

<table><br><thead><tr><th>user\item</th><th>item 1</th><th>item 2</th><th>item 3</th><th>item 4</th><th>item 5</th><th>item 6</th></tr></thead><br><tbody><br><tr><td>Ben</td><td>5</td><td>5</td><td>3</td><td>0</td><td>5</td><td>5</td></tr><br><tr><td>Tom</td><td>5</td><td>0</td><td>4</td><td>0</td><td>4</td><td>4</td></tr><br><tr><td>John</td><td>0</td><td>3</td><td>0</td><td>5</td><td>4</td><td>5</td></tr><br><tr><td>Fred</td><td>5</td><td>4</td><td>3</td><td>3</td><td>5</td><td>5</td></tr><br></tbody></table>

<h2 id="NMF"><a href="#NMF" class="headerlink" title="NMF"></a>NMF</h2><p>关于NMF，在<a href="/2014-12-22-latent-factor-model-and-nmf/">隐语义模型和NMF（非负矩阵分解）</a>已经有过介绍。</p>
<h3 id="用户和物品的主题分布"><a href="#用户和物品的主题分布" class="headerlink" title="用户和物品的主题分布"></a>用户和物品的主题分布</h3><pre><code># !/usr/bin/python2.7
# coding: UTF-8
import numpy as np
from sklearn.decomposition import NMF
import matplotlib.pyplot as plt

RATE_MATRIX = np.array(
    [[5, 5, 3, 0, 5, 5],
     [5, 0, 4, 0, 4, 4],
     [0, 3, 0, 5, 4, 5],
     [5, 4, 3, 3, 5, 5]]
)

nmf = NMF(n_components=2)  # 设有2个隐主题
user_distribution = nmf.fit_transform(RATE_MATRIX)
item_distribution = nmf.components_

print &#39;用户的主题分布：&#39;
print user_distribution
print &#39;物品的主题分布：&#39;
print item_distribution
</code></pre><p>运行后输出：</p>
<pre><code class="text">用户的主题分布：
[[ 2.20884275  0.84137492]
 [ 2.08253282 -0.        ]
 [-0.          3.18154406]
 [ 1.84992603  1.60839505]]
物品的主题分布：
[[ 2.4129931   1.02524235  1.62258152  0.          1.80111078  1.69591943]
 [ 0.0435741   1.13506094  0.          1.54526337  1.21253494  1.48756118]]
</code></pre>
<p>可视化物品的主题分布：</p>
<pre><code># !/usr/bin/python2.7
# coding: UTF-8
import numpy as np
from sklearn.decomposition import NMF
import matplotlib.pyplot as plt

RATE_MATRIX = np.array(
    [[5, 5, 3, 0, 5, 5],
     [5, 0, 4, 0, 4, 4],
     [0, 3, 0, 5, 4, 5],
     [5, 4, 3, 3, 5, 5]]
)

nmf = NMF(n_components=2)
user_distribution = nmf.fit_transform(RATE_MATRIX)
item_distribution = nmf.components_

item_distribution = item_distribution.T
plt.plot(item_distribution[:, 0], item_distribution[:, 1], &quot;b*&quot;)
plt.xlim((-1, 3))
plt.ylim((-1, 3))

plt.title(u&#39;the distribution of items (NMF)&#39;)
count = 1
for item in item_distribution:
    plt.text(item[0], item[1], &#39;item &#39;+str(count), bbox=dict(facecolor=&#39;red&#39;, alpha=0.2),)
    count += 1

plt.show()
</code></pre><p>结果：<br><img src="/content/images/2015/05/2015-05-25-nmf-svd-item-01.jpg" alt=""></p>
<p>从距离的角度来看，item 5和item 6比较类似；从余弦相似度角度看，item 2、5、6 比较相似，item 1、3比较相似。</p>
<p>可视化用户的主题分布：</p>
<pre><code># !/usr/bin/python2.7
# coding: UTF-8
import numpy as np
from sklearn.decomposition import NMF
import matplotlib.pyplot as plt

RATE_MATRIX = np.array(
    [[5, 5, 3, 0, 5, 5],
     [5, 0, 4, 0, 4, 4],
     [0, 3, 0, 5, 4, 5],
     [5, 4, 3, 3, 5, 5]]
)

nmf = NMF(n_components=2)
user_distribution = nmf.fit_transform(RATE_MATRIX)
item_distribution = nmf.components_

users = [&#39;Ben&#39;, &#39;Tom&#39;, &#39;John&#39;, &#39;Fred&#39;]
zip_data = zip(users, user_distribution)

plt.title(u&#39;the distribution of users (NMF)&#39;)
plt.xlim((-1, 3))
plt.ylim((-1, 4))
for item in zip_data:
    user_name = item[0]
    data = item[1]
    plt.plot(data[0], data[1], &quot;b*&quot;)
    plt.text(data[0], data[1], user_name, bbox=dict(facecolor=&#39;red&#39;, alpha=0.2),)

plt.show()
</code></pre><p>结果：</p>
<p><img src="/content/images/2015/05/2015-05-25-nmf-svd-user-01.jpg" alt=""></p>
<p>从距离的角度来看，Fred、Ben、Tom的口味差不多；从余弦相似度角度看，Fred、Ben、Tom的口味还是差不多。</p>
<h3 id="如何推荐"><a href="#如何推荐" class="headerlink" title="如何推荐"></a>如何推荐</h3><p>现在对于用户A，如何向其推荐物品呢？</p>
<p><strong>方法1：</strong> 找出与用户A最相似的用户B，将B评分过的、评分较高、A没评分过的的若干物品推荐给A。</p>
<p><strong>方法2：</strong> 找出用户A评分较高的若干物品，找出与这些物品相似的、且A没评分的若干物品推荐给A。</p>
<p><strong>方法3：</strong> 找出用户A最感兴趣的k个主题，找出最符合这k个主题的、且A没评分的若干物品推荐给A。</p>
<p><strong>方法4：</strong> 由NMF得到的两个矩阵，重建评分矩阵。例如：</p>
<pre><code># !/usr/bin/python2.7
# coding: UTF-8
import numpy as np
from sklearn.decomposition import NMF
import matplotlib.pyplot as plt

RATE_MATRIX = np.array(
    [[5, 5, 3, 0, 5, 5],
     [5, 0, 4, 0, 4, 4],
     [0, 3, 0, 5, 4, 5],
     [5, 4, 3, 3, 5, 5]]
)

RATE_MATRIX[1, 2] = 0  # 对评分矩阵略做修改
print &#39;新评分矩阵：&#39;
print RATE_MATRIX

nmf = NMF(n_components=2)
user_distribution = nmf.fit_transform(RATE_MATRIX)
item_distribution = nmf.components_

reconstruct_matrix = np.dot(user_distribution, item_distribution)
filter_matrix = RATE_MATRIX &lt; 1e-6  # 小于0
print &#39;重建矩阵，并过滤掉已经评分的物品：&#39;
print reconstruct_matrix*filter_matrix
</code></pre><p>运行结果：</p>
<pre><code class="text">新评分矩阵：
[[5 5 3 0 5 5]
 [5 0 0 0 4 4]
 [0 3 0 5 4 5]
 [5 4 3 3 5 5]]
重建矩阵，并过滤掉已经评分的物品：
[[ 0.          0.          0.          0.80443133  0.          0.        ]
 [ 0.          2.19148602  1.73560797  0.          0.          0.        ]
 [ 0.02543568  0.          0.48692891  0.          0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.        ]]
</code></pre>
<p>对于Tom（评分矩阵的第2行），其未评分过的物品是item 2、item 3、item 4。item 2的推荐值是<code>2.19148602</code>，item 3的推荐值是<code>1.73560797</code>，item 4的推荐值是<code>0</code>，若要推荐一个物品，推荐item 2。</p>
<h3 id="如何处理有评分记录的新用户"><a href="#如何处理有评分记录的新用户" class="headerlink" title="如何处理有评分记录的新用户"></a>如何处理有评分记录的新用户</h3><p>NMF是将非负矩阵V分解为两个非负矩阵W和H：</p>
<pre><code>V = W×H
</code></pre><p>在本文上面的实现中，V对应评分矩阵，W是用户的主题分布，H是物品的主题分布。</p>
<p>对于有评分记录的新用户，如何得到其主题分布？</p>
<p><strong>方法1：</strong> 有评分记录的新用户的评分数据放入评分矩阵中，使用NMF处理新的评分矩阵。</p>
<p><strong>方法2：</strong> 物品的主题分布矩阵H保持不变，将V更换为新用户的评分组成的行向量，求W即可。</p>
<p>下面尝试一下方法2。</p>
<p>设新用户Bob的评分记录为：</p>
<pre><code>[5,5,0,0,0,5]
</code></pre><pre><code># !/usr/bin/python2.7
# coding: UTF-8
import numpy as np
from sklearn.decomposition import NMF
import matplotlib.pyplot as plt

RATE_MATRIX = np.array(
    [[5, 5, 3, 0, 5, 5],
     [5, 0, 4, 0, 4, 4],
     [0, 3, 0, 5, 4, 5],
     [5, 4, 3, 3, 5, 5]]
)

nmf = NMF(n_components=2)
user_distribution = nmf.fit_transform(RATE_MATRIX)
item_distribution = nmf.components_

bob = [5, 5, 0, 0, 0, 5]
print &#39;Bob的主题分布：&#39;
print nmf.transform(bob)
</code></pre><p>运行结果是：</p>
<pre><code class="text">Bob的主题分布：
[[ 1.37800534  0.69236738]]
</code></pre>
<p><img src="/content/images/2015/05/2015-05-25-nmf-svd-user-02.jpg" alt=""></p>
<h2 id="经典SVD"><a href="#经典SVD" class="headerlink" title="经典SVD"></a>经典SVD</h2><p>关于SVD的一篇好文章：<a href="http://www.cnblogs.com/leftnoteasy/archive/2011/01/19/svd-and-applications.html" target="_blank" rel="external">强大的矩阵奇异值分解(SVD)及其应用</a>。</p>
<p>相关分析与上面类似，这里就直接上代码了。</p>
<pre><code># !/usr/bin/python2.7
# coding: UTF-8
import numpy as np
from scipy.sparse.linalg import svds
from scipy import sparse
import matplotlib.pyplot as plt

def vector_to_diagonal(vector):
    &quot;&quot;&quot;
    将向量放在对角矩阵的对角线上
    :param vector:
    :return:
    &quot;&quot;&quot;
    if (isinstance(vector, np.ndarray) and vector.ndim == 1) or \
            isinstance(vector, list):
        length = len(vector)
        diag_matrix = np.zeros((length, length))
        np.fill_diagonal(diag_matrix, vector)
        return diag_matrix
    return None

RATE_MATRIX = np.array(
    [[5, 5, 3, 0, 5, 5],
     [5, 0, 4, 0, 4, 4],
     [0, 3, 0, 5, 4, 5],
     [5, 4, 3, 3, 5, 5]]
)

RATE_MATRIX = RATE_MATRIX.astype(&#39;float&#39;)
U, S, VT = svds(sparse.csr_matrix(RATE_MATRIX),  k=2, maxiter=200) # 2个隐主题
S = vector_to_diagonal(S)

print &#39;用户的主题分布：&#39;
print U
print &#39;奇异值：&#39;
print S
print &#39;物品的主题分布：&#39;
print VT
print &#39;重建评分矩阵，并过滤掉已经评分的物品：&#39;
print np.dot(np.dot(U, S), VT) * (RATE_MATRIX &lt; 1e-6)
</code></pre><p>运行结果：</p>
<pre><code class="text">用户的主题分布：
[[-0.22279713  0.57098887]
 [-0.51723555  0.4274751 ]
 [ 0.82462029  0.38459931]
 [ 0.05319973  0.58593526]]
奇异值：
[[  6.39167145   0.        ]
 [  0.          17.71392084]]
物品的主题分布：
[[-0.53728743  0.24605053 -0.40329582  0.67004393  0.05969518  0.18870999]
 [ 0.44721867  0.35861531  0.29246336  0.20779151  0.50993331  0.53164501]]
重建评分矩阵，并过滤掉已经评分的物品：
[[ 0.          0.          0.          1.14752376  0.          0.        ]
 [ 0.          1.90208543  0.         -0.64171368  0.          0.        ]
 [ 0.21491237  0.         -0.13316888  0.          0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.        ]]
</code></pre>
<p>可视化一下：<br><img src="/content/images/2015/05/2015-05-25-nmf-svd-user-item-svd.jpg" alt=""></p>
<h2 id="经典SVD-协同过滤"><a href="#经典SVD-协同过滤" class="headerlink" title="经典SVD + 协同过滤"></a>经典SVD + 协同过滤</h2><p><code>0</code>代表没有评分，但是上面的方法（<code>如何推荐</code>这一节的<code>方法4</code>）又确实把0看作了评分，所以最终得到的只是一个推荐值（而且总体都偏小），而无法当作预测的评分。在<a href="http://stats.stackexchange.com/questions/31096/how-do-i-use-the-svd-in-collaborative-filtering" target="_blank" rel="external">How do I use the SVD in collaborative filtering?</a>有这方面的讨论。</p>
<h3 id="SVD简要介绍"><a href="#SVD简要介绍" class="headerlink" title="SVD简要介绍"></a>SVD简要介绍</h3><p>SVD的目标是将<code>m*n</code>大小的矩阵A分解为三个矩阵的乘积：</p>
<p>[latex]<br>A = U <em> S </em> V^{T}<br>[/latex]</p>
<p>U和V都是正交矩阵，大小分别是<code>m*m</code>、<code>n*n</code>。S是一个对角矩阵，大小是<code>m*n</code>，对角线存放着奇异值，从左上到右下依次减小，设奇异值的数量是<code>r</code>。</p>
<p>取<code>k</code>，<code>k&lt;&lt;r</code>。</p>
<p>取得[latex]U[/latex]的前k列得到[latex]U_{k}[/latex]，[latex]S[/latex]的前k个奇异值对应的方形矩阵得到[latex]S_{k}[/latex]，[latex]V^{T}[/latex]的前k行得到[latex]V^{T}_{k}[/latex]，于是有</p>
<p>[latex]<br>A_{k} = U_{k} <em> S_{k} </em> V^{T}_{k}<br>[/latex]</p>
<p>[latex]A_{k}[/latex]可以认为是[latex]A[/latex]的近似。</p>
<p>下面的算法将协同过滤和SVD结合了起来。</p>
<h3 id="Item-based-Filtering-Enhanced-by-SVD"><a href="#Item-based-Filtering-Enhanced-by-SVD" class="headerlink" title="Item-based Filtering Enhanced by SVD"></a>Item-based Filtering Enhanced by SVD</h3><p>这个算法来自下面这篇论文：</p>
<blockquote>
<p>Vozalis M G, Margaritis K G. Applying SVD on Generalized Item-based Filtering[J]. IJCSA, 2006, 3(3): 27-51.</p>
</blockquote>
<p><strong>1、</strong> 设评分矩阵为<code>R</code>，大小为<code>m*n</code>，m个用户，n个物品。<code>R</code>中元素[latex]r_{ij}[/latex]代表着用户[latex]u_{i}[/latex]对物品[latex]i_{j}[/latex]的评分。</p>
<p><strong>2、</strong> 预处理<code>R</code>，消除掉其中未评分数据（即值为0）的评分。</p>
<ul>
<li>计算<code>R</code>中每一行的平均值（平均值的计算中不包括值为0的评分），令[latex]R_{filled-in}=R[/latex]，然后将[latex]R_{filled-in}[/latex]中的0设置为该行的平均值。</li>
<li>计算<code>R</code>中每一列的平均值（平均值的计算中不包括值为0的评分）[latex]r_{i}[/latex]，[latex]R_{filled-in}[/latex]中的所有元素减去对应的[latex]r_{i}[/latex]，得到正规化的矩阵[latex]R_{norm}[/latex]。(norm，即normalized)。</li>
</ul>
<p><strong>3、</strong> 对[latex]R_{norm}[/latex]进行奇异值分解，得到：<br>[latex]<br>R_{norm} = U <em> S </em> V^{T}<br>[/latex]</p>
<p><strong>4、</strong> 设正整数k，取得[latex]U[/latex]的前k列得到[latex]U_{k}[/latex]，[latex]S[/latex]的前k个奇异值对应的方形矩阵得到[latex]S_{k}[/latex]，[latex]V^{T}[/latex]的前k行得到[latex]V^{T}_{k}[/latex]，于是有</p>
<p>[latex]<br>R_{red} = U_{k} <em> S_{k} </em> V^{T}_{k}<br>[/latex]</p>
<p>red，即dimensionality reduction中的reduction。可以认为k是指最重要的k个主题。定义[latex]R_{red}[/latex]中元素[latex]rr_{ij}[/latex]用户i对物品j在矩阵[latex]R_{red}[/latex]中的值。</p>
<p><strong>5、</strong> [latex] U_{k} <em> S_{k}^{\frac{1}{2}}[/latex]，是用户相关的降维后的数据，其中的每行代表着对应用户在新特征空间下位置。[latex] S_{k}^{\frac{1}{2}}</em>V^{T}_{k}[/latex]，是物品相关的降维后的数据，其中的每列代表着对应物品在新特征空间下的位置。</p>
<p>[latex] S_{k}^{\frac{1}{2}}*V^{T}_{k}[/latex]中的元素[latex]mr_{ij}[/latex]代表<code>物品j</code>在新空间下<code>维度i</code>中的值，也可以认为是<code>物品j</code>属于<code>主题i</code>的程度。（共有k个主题）。</p>
<p><strong>6、</strong> 获取物品之间相似度。</p>
<ul>
<li><p>根据[latex] S_{k}^{\frac{1}{2}}*V^{T}_{k}[/latex]计算物品之间的相似度，例如使用余弦相似度计算物品j和f的相似度：<br><img src="/content/images/2015/05/2015-05-25-nmf-svd-formula-01.png" alt=""></p>
</li>
<li><p>相似度计算出来后就可以得到每个物品最相似的若干物品了。</p>
</li>
</ul>
<p><strong>7、</strong> 使用下面的公式预测用户a对物品j的评分：<br><img src="/content/images/2015/05/2015-05-25-nmf-svd-formula-02.png" alt=""><br>这个公式里有些变量的使用和上面的冲突了（例如k）。<br>[latex]l[/latex]是指取物品j最相似的[latex]l[/latex]个物品。<br>[latex]mr_{ij}[/latex]代表<code>物品j</code>在新空间下<code>维度i</code>中的值，也可以认为是<code>物品j</code>属于<code>主题i</code>的程度。<br>[latex]sim_{jk}[/latex]是物品j和物品k的相似度。<br>[latex]R_{red}[/latex]中元素[latex]rr_{ak}[/latex]是用户a对物品k在矩阵[latex]R_{red}[/latex]中对应的评分。[latex]\bar{r_{a}}[/latex]是指用户a在评分矩阵[latex]R[/latex]中评分的平均值（平均值的计算中不包括值为0的评分）。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.igvita.com/2007/01/15/svd-recommendation-system-in-ruby/" target="_blank" rel="external">SVD Recommendation System in Ruby</a>  这篇文章使用的数据来自该链接，里面处理新用户的方法表示没看懂。</p>
<p><a href="http://stats.stackexchange.com/questions/31096/how-do-i-use-the-svd-in-collaborative-filtering" target="_blank" rel="external">How do I use the SVD in collaborative filtering?</a></p>
<p>Vozalis M G, Margaritis K G. Applying SVD on Generalized Item-based Filtering[J]. IJCSA, 2006, 3(3): 27-51.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://www.letiantian.me/topic-learn-flask/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Letian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/content/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="樂天笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/topic-learn-flask/" itemprop="url">专题：浅入浅出Flask框架</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2015-05-17T10:12:36+08:00">
                May 17th 2015
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="/content/images/2015/05/2015-05-17-flask-logo.jpg" alt=""></p>
<blockquote>
<p>Flask is a microframework for Python based on Werkzeug, Jinja 2 and good intentions. And before you ask: It’s BSD licensed!</p>
</blockquote>
<p><a href="http://flask.pocoo.org/" target="_blank" rel="external">Flask官方网址</a></p>
<p><a href="/2014-06-01-ubuntu-install-flask/">浅入浅出Flask框架：在ubuntu下安装Flask</a></p>
<p><a href="/2014-06-01-flask-hello-world/">浅入浅出Flask框架：从HelloWorld开始Flask</a></p>
<p><a href="/2014-06-23-flask-get-url-params/">浅入浅出Flask框架：获取URL参数</a></p>
<p><a href="/2014-06-24-flask-process-post-data/">浅入浅出Flask框架：处理客户端通过POST方法传送的数据</a></p>
<p><a href="/2014-06-28-flask-restful-url/">浅入浅出Flask框架：RESTful URL</a> </p>
<p><a href="/2014-06-28-flask-url-for/">浅入浅出Flask框架：url_for</a></p>
<p><a href="/2014-06-28-flask-redirect/">浅入浅出Flask框架：使用redirect</a></p>
<p><a href="/2014-06-28-flask-jinja2-template-engine/">浅入浅出Flask框架：使用Jinja2模板引擎</a>  </p>
<p><a href="/2014-06-28-flask-handle-errors/">浅入浅出Flask框架：自定义404等错误</a>  </p>
<p><a href="/2014-06-28-flask-session/">浅入浅出Flask框架：用户会话</a>  </p>
<p><a href="/2014-06-28-flask-cookie/">浅入浅出Flask框架：Cookie</a></p>
<p><a href="/2014-06-29-flask-flash/">浅入浅出Flask框架：flashing system</a></p>
<p><a href="/2014-06-30-flask-datum-collected/">Flask框架资料整理</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://www.letiantian.me/2015-05-17-alibaba-mobile-recommend-competition-summary/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Letian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/content/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="樂天笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2015-05-17-alibaba-mobile-recommend-competition-summary/" itemprop="url">2015阿里移动推荐算法比赛第一赛季总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2015-05-17T09:59:41+08:00">
                May 17th 2015
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>2015-05-17</p>
<p>第一赛季是在四月底结束，分数还凑合，过了9.00%。本文只是一篇总结性的文章。</p>
<p>发现的问题：<br>1、还是学的不怎么样<br>2、了解的不够深入，实战经验少<br>3、PRML和NG的视频都没看，不算好好学过机器学习<br>4、论文看得太少<br>5、没人指点<br>6、机器设备太差<br>7、比赛参加的有点晚，中间还出去溜达了几天<br>8、单人作战很酸爽～</p>
<h2 id="比赛题目"><a href="#比赛题目" class="headerlink" title="比赛题目"></a>比赛题目</h2><p>官方提供了两个文本文件，第一个是<code>tianchi_mobile_recommend_train_user.csv</code>：</p>
<pre><code class="text">user_id,item_id,behavior_type,user_geohash,item_category,time
99512554,37320317,3,94gn6nd,9232,2014-11-26 20
9909811,266982489,1,,3475,2014-12-02 23
......
</code></pre>
<p>每一行代表了用户<code>user_id</code>对属于分类<code>cat_id</code>的物品<code>item_id</code>在<code>time</code>这个时间于地点<code>user_geohash</code>发生了交互，交互类型是<code>behavior_type</code>。<code>behavior_type</code>包括浏览、收藏、加购物车、购买，对应取值分别是1、2、3、4。<code>tianchi_mobile_recommend_train_user.csv</code>中的数据约有1200万行。</p>
<p>一共有31天的交互数据，最后要预测地32天有哪些user会购买哪些item。 举办方对你提交的数据计算F1，并进行排名。</p>
<p>然而，还有一个商品子集的文件<code>tianchi_mobile_recommend_train_item.csv</code>：</p>
<pre><code>item_id,item_geohash,item_category
327414838,,11991
169831798,,7876
320523991,,3370
......
</code></pre><p>这个文件约有44万条数据，是<code>tianchi_mobile_recommend_train_user.csv</code>中出现的item的一个子集。官方的第32天的会发生购买的<code>user, item</code>中的item都是这个文件中的item，所以我们预测的<code>user, item</code>需要根据这个文件来过滤掉一些结果。</p>
<h2 id="基本思路"><a href="#基本思路" class="headerlink" title="基本思路"></a>基本思路</h2><p>这个预测，可以考虑预测<strong>发生过交互行为</strong>的<code>user, item</code>会不会在第32天购买，也可以预测<strong>没有发生过交互行为</strong>的<code>user, item</code>会不会在第32天购买。笔者这一次只考虑了<strong>发生过交互行为</strong>的<code>user, item</code>。我们要有一份自己的训练集和测试集来评估自己的模型（算法），当觉得自己的模型比较好了，就可以拿着模型去预测了。</p>
<h2 id="清洗数据"><a href="#清洗数据" class="headerlink" title="清洗数据"></a>清洗数据</h2><p>比如去除总的交互次数很低（低于2或者低于3或者…）的<code>user, item</code>，去除最后10天没有发生交互的<code>user, item</code>。还可以继续删除，比如双12的所有数据。不过删多了可不一定好。</p>
<h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><blockquote>
<p>一个简单算法在精心选择的特征上的效果比一个漂亮的算法在较差的特征上的效果还要好。</p>
</blockquote>
<p>如何构造特征很重要，特征构造得好，同一算法下准确率也可以提升很多。个人认为构造特征是这次比赛中最重要的任务。</p>
<p>以<a href="http://zh.wikipedia.org/wiki/%E5%AE%89%E5%BE%B7%E6%A3%AE%E9%B8%A2%E5%B0%BE%E8%8A%B1%E5%8D%89%E6%95%B0%E6%8D%AE%E9%9B%86" target="_blank" rel="external">Iris数据集</a>为例，其默认提供了4个特征：花萼和花瓣的长度和宽度。对此我们可以构造更多的特征，例如<code>花萼宽度/花萼长度</code>、<code>花萼宽度/花瓣长度</code>、<code>花萼宽度×花萼长度</code>等等，只要觉得合理，就可以构造。</p>
<p>另外，特征的优劣会影响到一些机器学习算法的效果，或者特征太多机器会跑不动。筛选特征可能会成为一个很重要的步骤。假设现在有100个有标号的样本，每个样本10个特征，可以通过下面几种方法：</p>
<p><strong>方法1：</strong> 拿出两个特征对应的两个100维的向量，使用pearson相关系数、归一化互信息量等方法计算两个特征的相关性，如果相关性很高，可以考虑删除其中一个特征。</p>
<p><strong>方法2：</strong> 利用决策树的内置的特征筛选方法筛选好的特征</p>
<p><strong>方法3：</strong>特征递归消除。可以参考<a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html" target="_blank" rel="external">http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html</a>。</p>
<p>scikit-learn库提供了多个特征选择的方法，<a href="http://scikit-learn.org/stable/modules/feature_selection.html" target="_blank" rel="external">点这里</a>。 </p>
<p>也可以考虑降维。<a href="http://scikit-learn.org/stable/modules/decomposition.html" target="_blank" rel="external">点这里</a>。</p>
<p><strong>那么，一个<code>user, item</code>可以构造什么特征呢？</strong></p>
<p>以前30天的所有数据为例（第31天有没有购买当作target）： 最后一天user有没有购买item、最后的4天user有没有购买item、最后的4天user有没有点击item、最后的4天user对item的点击量、最后的4到8天user对item的点击量，最后的4天user的点击量，最后的4天item的的点击量，最后的4天item的的购买量除最后的4天item的的点击量……  <strong>去年比赛的PPT中都讲到了这些</strong>。 另外,geohash也可以拿来生成特征，例如判断用户的最新位置和item最近的位置有多近；<code>cat_id</code>也可以考虑一下。再开个脑洞，将<code>user, item</code>的构造的某些特征进行聚类，样本所属的簇、样本离某个簇心的距离等也可以当作该样本的新特征。</p>
<h2 id="训练集和测试集的构造"><a href="#训练集和测试集的构造" class="headerlink" title="训练集和测试集的构造"></a>训练集和测试集的构造</h2><p>基于上面的内容，现在可以构造训练集和测试集了。</p>
<ul>
<li>新数据集1： 将1-27天的数据拿出来做特征，第28天作为target。 -&gt; 用于训练  </li>
<li>新数据集2： 将2-28天的数据拿出来做特征，第29天作为target。 -&gt; 用于训练  </li>
<li>新数据集3： 将3-29天的数据拿出来做特征，第30天作为target。 -&gt; 用于训练</li>
<li>新数据集4： 将4-30天的数据拿出来做特征，第31天作为target。 -&gt; 用于测试</li>
<li>新数据集5： 将5-31天的数据拿出来做特征。 -&gt; 用于最终的预测。</li>
</ul>
<p><strong>正负样本比例问题：</strong> 对于上面生成的一个数据集，正例（target是购买）的数量只是几千，而负例上百万。只能说太不平衡了，不适合做训练集。可以这样做：将多个数据集的正例放在一起以增加正例数量；对负例进行随机采样。可以考虑生成多个训练集来观察模型的稳定性。</p>
<p><strong>如何评估模型：</strong> 用<code>新数据集4</code>做测试，其实只需要把<code>新数据集4</code>其中的正例拿出来，计算F1即可。如果这个F1做的比较好了，可以认为提交结果的F1也会很好。</p>
<h2 id="分类还是回归？"><a href="#分类还是回归？" class="headerlink" title="分类还是回归？"></a>分类还是回归？</h2><p>很明显，这是一个二分类问题。不过如果只看做二分类，会出一些问题。举办方那边有约500条数据（从第32天的实际购买<code>user, item</code>抽取出来的）来计算参赛者提交数据的F1，如果你只预测了100个<code>user, item</code> 或者预测了2000条<code>user, item</code>，这些数据并不适合提交上去，提交的比较好的数据量是400~1200之间。</p>
<p>利用回归来解决是个不错的思路。基于回归的预测结果可以简单看成user会购买item的概率，概率越高，购买的可能性越大。通过设置一个<code>阈值</code>就可以得到任意数量的提交结果了。</p>
<h2 id="机器学习库、机器学习方法"><a href="#机器学习库、机器学习方法" class="headerlink" title="机器学习库、机器学习方法"></a>机器学习库、机器学习方法</h2><p>网上能找到很多机器学习库，例如scikit-learn、Spark MLlib、Apache Mahout、R等。</p>
<p>上两个网址：<br><a href="http://www.infoq.com/cn/news/2014/12/11-machine-learning-project" target="_blank" rel="external">InfoQ：机器学习的11个开源项目</a><br><a href="http://www.zhihu.com/question/20472776" target="_blank" rel="external">知乎：请问学习机器学习有哪些好工具推荐呢？</a>  </p>
<p>scikit-learn支持很多机器学习方法，列举一二：</p>
<p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" target="_blank" rel="external">Logistic Regression</a>：分类器，<code>predict_proba()</code>函数可以当作回归来使用。</p>
<p><a href="http://scikit-learn.org/stable/modules/tree.html#classification" target="_blank" rel="external">决策树 - 分类</a> </p>
<p><a href="http://scikit-learn.org/stable/modules/tree.html#regression" target="_blank" rel="external">决策树 - 回归</a>  </p>
<p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" target="_blank" rel="external">随机森林 - 分类</a>  </p>
<p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html" target="_blank" rel="external">随机森林 - 回归</a>  </p>
<p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html" target="_blank" rel="external">GBDT - 分类</a></p>
<p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html" target="_blank" rel="external">GBDT - 回归</a>  </p>
<p>Spark 的机器学习库<a href="http://spark.apache.org/mllib/" target="_blank" rel="external">MLlib</a>提供的方法也不少，可以进入<a href="http://spark.apache.org/docs/latest/mllib-guide.html" target="_blank" rel="external">Machine Learning Library (MLlib) Guide</a>了解一下。</p>
<p>只用1个算法去预测的队伍应该挺多，也可以考虑多个经典机器学习算法融合到一起（<a href="http://en.wikipedia.org/wiki/Ensemble_learning" target="_blank" rel="external">Ensemble learning</a>）。</p>
<p><strong>参数调优</strong><br>每个模型都有很多参数，参数的选择也会影响到最后的效果。思路：</p>
<p>1、手动调参数；<br>2、枚举一些参数值，一个个测试；<br>3、遗传算法、粒子群算法等。  </p>
<p><strong>方差和偏差问题</strong></p>
<p>训练后的模型测试的效果很差，叫做高偏差，这往往意味着模型太简单。解决方法是：增加更多特征、使用别的模型、使用更复杂的模型等。</p>
<p>同一模型，用随机采样的多个数据集训练并测试的多个结果相差很大，叫做高方差，这往往意味着模型太复杂，导致了过拟合。解决方法是：使用更多数据、降低模型复杂度等。</p>
<h2 id="单机还是集群？"><a href="#单机还是集群？" class="headerlink" title="单机还是集群？"></a>单机还是集群？</h2><p>这次比赛数据量偏大，要不加内存，要不用集群。</p>
<h2 id="提交多少数据？"><a href="#提交多少数据？" class="headerlink" title="提交多少数据？"></a>提交多少数据？</h2><p>同一模型、同一训练集得到的预测结果，通过<code>阈值</code>可以得到不同数量的结果，提交1000条结果和提交600条结果的F1分数可能差距很大，提交600条结果和提交560条结果的F1分数也可能差距很大。如果模型做得足够好的话，提交400～1000条数据都能得到很好的F1分数；如果模型方面到瓶颈了，就需要好好考虑提交多少条数据比较好了。</p>
<h2 id="其他工具"><a href="#其他工具" class="headerlink" title="其他工具"></a>其他工具</h2><p>使用MapReduce对数据做预处理。<br>存储基本特征、中间结果等考虑使用数据库（MySQL或者MongoDB）。</p>
<h2 id="如何查找作弊现象"><a href="#如何查找作弊现象" class="headerlink" title="如何查找作弊现象"></a>如何查找作弊现象</h2><p>想了想，可以是下面的一些方法：<br>1、两个队伍提交的数据完全相同（先排序，再求编辑距离）<br>2、两个队伍提交时使用的IP相同，但是不同的队伍可能用同一个代理<br>3、一个浏览器提交了多个队伍的数据（在浏览器中加入cookie）<br>4、实名认证<br>5、提交代码，代码查重  </p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>收获很多，自己在机器学习这方面还有很大进步空间。</p>
<p>学习并使用了Spark的MLlib。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://www.letiantian.me/topic-learn-mybatis-from-scratch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Letian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/content/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="樂天笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/topic-learn-mybatis-from-scratch/" itemprop="url">专题：浅入浅出MyBatis</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2015-05-17T09:16:59+08:00">
                May 17th 2015
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>MyBatis 是支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架。MyBatis 避免了几乎所有的 JDBC 代码和手工设置参数以及抽取结果集。MyBatis 使用简单的 XML 或注解来配置和映射基本体，将接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录。</p>
</blockquote>
<p><a href="/2015-01-14-learn-mybatis-from-scratch-01">浅入浅出MyBatis(01)：查询id为1的用户的信息</a></p>
<p><a href="/2015-01-14-learn-mybatis-from-scratch-02">浅入浅出MyBatis(02)：查询密码为123的所有用户</a></p>
<p><a href="/2015-01-14-learn-mybatis-from-scratch-03">浅入浅出MyBatis(03)：如果Bean中成员变量和表中字段命名不一致</a></p>
<p><a href="/2015-01-14-learn-mybatis-from-scratch-04">浅入浅出MyBatis(04)：只获取表中的部分字段</a></p>
<p><a href="/2015-01-14-learn-mybatis-from-scratch-05">浅入浅出MyBatis(05)：插入数据</a></p>
<p><a href="/2015-01-14-learn-mybatis-from-scratch-06">浅入浅出MyBatis(06)：更新数据</a></p>
<p><a href="/2015-01-14-learn-mybatis-from-scratch-07">浅入浅出MyBatis(07)：删除数据</a></p>
<p><a href="/2015-01-14-learn-mybatis-from-scratch-08">浅入浅出MyBatis(08)：获取一个用户的所有blog</a></p>
<p><a href="/2015-01-14-learn-mybatis-from-scratch-09">浅入浅出MyBatis(09)：获取一篇文章及其作者的信息</a></p>
<p><a href="/2015-01-14-learn-mybatis-from-scratch-10">浅入浅出MyBatis(10)：分页查询</a></p>
<p><a href="/2015-01-14-learn-mybatis-from-scratch-11">浅入浅出MyBatis(11)：动态SQL</a></p>
<p><a href="/2015-01-14-learn-mybatis-from-scratch-12">浅入浅出MyBatis(12)：使用事务</a></p>
<p><a href="/2015-01-14-learn-mybatis-from-scratch-13">浅入浅出MyBatis(13)：关于连接池</a></p>
<p><a href="/2015-01-14-learn-mybatis-from-scratch-14">浅入浅出MyBatis(14)：使用注解</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://www.letiantian.me/2015-04-03-pca-lda-nmf-iris/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Letian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/content/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="樂天笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2015-04-03-pca-lda-nmf-iris/" itemprop="url">在Iris数据集上对比PCA、LDA、NMF</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2015-04-03T21:49:13+08:00">
                April 3rd 2015
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>2015-04-03</p>
<p>PCA、LDA、NMF都可以用来降维。</p>
<p>之前在<a href="/2014-12-23-pca-mnist/">使用PCA处理MNIST数据集</a>介绍过PCA，在<a href="/2014-12-22-latent-factor-model-and-nmf/">隐语义模型和NMF（非负矩阵分解）</a>介绍过NMF。</p>
<p>这里的LDA，是指线性判别分析（Linear Discriminant Analysis），是一种有监督的学习方法。这方面的资料可以参考：  </p>
<blockquote>
<p>PRML（Pattern Recognition and Machine Learning）第四章 </p>
<p><a href="http://www.cnblogs.com/LeftNotEasy/archive/2011/01/08/lda-and-pca-machine-learning.html" target="_blank" rel="external">机器学习中的数学(4)-线性判别分析（LDA）, 主成分分析(PCA)</a>  </p>
<p><a href="http://www.cnblogs.com/jerrylead/archive/2011/04/21/2024384.html" target="_blank" rel="external">线性判别分析（Linear Discriminant Analysis）（一）</a>  </p>
</blockquote>
<p>本文内容是如何使用scikit-learn中的这3个降维工具处理Iris数据集，并用图的形式比较了降维效果。</p>
<h2 id="导入数据集"><a href="#导入数据集" class="headerlink" title="导入数据集"></a>导入数据集</h2><hr>
<pre><code>&gt;&gt;&gt; from sklearn.datasets import load_iris
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; iris = load_iris()
&gt;&gt;&gt; iris.data
array([[ 5.1,  3.5,  1.4,  0.2],  
       [ 4.9,  3. ,  1.4,  0.2],
       ....
       [ 5.9,  3. ,  5.1,  1.8]])
&gt;&gt;&gt; iris.target
array([0, 0, 0, 0, 0, 0, ... , 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,  
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
&gt;&gt;&gt; iris.data.shape  
(150, 4)                   # 150个样本，每个样本4个特征
&gt;&gt;&gt; iris.target.shape      # 每个样本的类别
(150,)
</code></pre><h2 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h2><hr>
<pre><code>&gt;&gt;&gt; from sklearn.decomposition import PCA
&gt;&gt;&gt; pca = PCA(n_components=2)
&gt;&gt;&gt; pca_result = pca.fit_transform(iris.data)
</code></pre><h2 id="LDA"><a href="#LDA" class="headerlink" title="LDA"></a>LDA</h2><hr>
<pre><code>&gt;&gt;&gt; from sklearn.lda import LDA
&gt;&gt;&gt; lda = LDA()
&gt;&gt;&gt; lda = LDA(n_components=2)
&gt;&gt;&gt; lda_result = lda.fit_transform(iris.data, iris.target)
</code></pre><h2 id="NMF"><a href="#NMF" class="headerlink" title="NMF"></a>NMF</h2><hr>
<pre><code>&gt;&gt;&gt; from sklearn.decomposition import NMF
&gt;&gt;&gt; nmf = NMF(n_components=2)
&gt;&gt;&gt; nmf_result = nmf.fit_transform(iris.data)
</code></pre><h2 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h2><hr>
<pre><code>&gt;&gt;&gt; import matplotlib.pyplot as plt
# for PCA
&gt;&gt;&gt; plt.subplot(1,3,1)
&gt;&gt;&gt; plt.scatter(pca_result[iris.target==0, 0], pca_result[iris.target==0, 1], color=&#39;r&#39;)
&gt;&gt;&gt; plt.scatter(pca_result[iris.target==1, 0], pca_result[iris.target==1, 1], color=&#39;g&#39;) 
&gt;&gt;&gt; plt.scatter(pca_result[iris.target==2, 0], pca_result[iris.target==2, 1], color=&#39;b&#39;) 
&gt;&gt;&gt; plt.title(&#39;PCA on iris&#39;)

# for LDA
&gt;&gt;&gt; plt.subplot(1,3,2)
&gt;&gt;&gt; plt.scatter(lda_result[iris.target==0, 0], lda_result[iris.target==0, 1], color=&#39;r&#39;)
&gt;&gt;&gt; plt.scatter(lda_result[iris.target==1, 0], lda_result[iris.target==1, 1], color=&#39;g&#39;) 
&gt;&gt;&gt; plt.scatter(lda_result[iris.target==2, 0], lda_result[iris.target==2, 1], color=&#39;b&#39;) 
&gt;&gt;&gt; plt.title(&#39;LDA on iris&#39;)

# for NMF
&gt;&gt;&gt; plt.subplot(1,3,3)
&gt;&gt;&gt; plt.scatter(nmf_result[iris.target==0, 0], nmf_result[iris.target==0, 1], color=&#39;r&#39;)
&gt;&gt;&gt; plt.scatter(nmf_result[iris.target==1, 0], nmf_result[iris.target==1, 1], color=&#39;g&#39;) 
&gt;&gt;&gt; plt.scatter(nmf_result[iris.target==2, 0], nmf_result[iris.target==2, 1], color=&#39;b&#39;) 
&gt;&gt;&gt; plt.title(&#39;NMF on iris&#39;)

&gt;&gt;&gt; plt.show()
</code></pre><h2 id="查看效果"><a href="#查看效果" class="headerlink" title="查看效果"></a>查看效果</h2><hr>
<p><img src="/content/images/2015/04/2015-04-03-pca-lda-nmf.png" alt=""></p>
<p>每副图中的灰色直线是我添加上去的，这些直线可以看出新数据的不同特点。</p>
<p>（完）</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/24/">24</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/content/images/avatar.jpg"
               alt="Letian" />
          <p class="site-author-name" itemprop="name">Letian</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">209</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">43</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/letiantian" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Letian</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.1"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  
    
    <script>
      var cloudTieConfig = {
        url: document.location.href, 
        sourceId: "",
        productKey: "0b5e0b416d0b4d9a845ed9b2e72ddc70",
        target: "cloud-tie-wrapper"
      };
    </script>
    <script src="https://img1.ws.126.net/f2e/tie/yun/sdk/loader.js"></script>
  










  





  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['[latex]','[/latex]'], ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        },
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  


  <!-- highlight -->
  <script src="/highlight/highlight.min.js"></script>
  <link rel="stylesheet" href="/highlight/styles/github.css">

  <script>
    // 高亮
    hljs.initHighlightingOnLoad();
  </script>

</body>
</html>
